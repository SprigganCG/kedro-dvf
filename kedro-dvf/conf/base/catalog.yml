# Here you can define all your datasets by using simple YAML syntax.
#
# Documentation for this file format can be found in "The Data Catalog"
# Link: https://docs.kedro.org/en/stable/data/data_catalog.html


_csv: &csv
  type: pandas.CSVDataset
  load_args:
    sep: "|"
    compression: 'zip'
    encoding: "utf-8"
    decimal: '.'
    date_format: "%d/%m/%Y"
    low_memory: False
    parse_dates: True
  metadata:
    kedro-viz:
      layer: raw

# dvf data for each year
raw-dvf-2024:
  <<: *csv
  filepath: https://www.data.gouv.fr/fr/datasets/r/5ffa8553-0e8f-4622-add9-5c0b593ca1f8

raw-dvf-2023:
  <<: *csv
  filepath: https://www.data.gouv.fr/fr/datasets/r/bc213c7c-c4d4-4385-bf1f-719573d39e90


# intermediate series of datasets
int-imported-dvf.{year}:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/imported/int-imported-dvf.{year}.parquet
  metadata:
    kedro-viz:
      layer: intermediate

int-reduced-dvf.{year}:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/reduced/int-reduced-dvf.{year}.parquet
  metadata:
    kedro-viz:
      layer: intermediate

int-filtered-dvf.{year}:
  type: pandas.ParquetDataset
  filepath: data/02_intermediate/filtered/int-filtered-dvf.{year}.parquet
  metadata:
    kedro-viz:
      layer: intermediate


# partitioned dataset
int-preprocessed-dvf:
  type: partitions.PartitionedDataset
  path: data/02_intermediate/preprocessed/
  dataset:
    type: pandas.ParquetDataset
  filename_suffix: ".parquet"
  save_lazily: True
  metadata:
    kedro-viz:
      layer: intermediate